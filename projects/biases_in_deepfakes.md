# Biases in Deep Fake Videos Using Deep Learning Technology

-	**Project Years:** 01/2022 to 05/2022

-	**Project Conducted as part of:** Master’s Program at University of Southern California for the Coursework DSCI 531: Fairness in Artificial Intelligence

**Description of project:** 
This project investigates gender and fat anti-fat biases present in DeepFake-generated videos using the FaceForensics++ dataset, which contains 500 videos manipulated through the FaceSwap DeepFake generator. The dataset primarily consists of Caucasian subjects, with a significant gender imbalance favoring females. By applying multiple deep learning techniques—GRU, RNN, and CNN—the study found that CNNs performed best in doing visual based classification. Misclassifications that were identified were further studied and it was noted that traditional physical traits, like women with short hair or wearing formal clothes, were wrongly classified as male. The study also included an extended societal bias survey where participants were shown images of obese individuals and were requested to provide their views. The study revealed that females tend to be more critical of physical traits in obese individuals in the survey

## Technologies Used
Tensorflow, Pandas, Keras, Deep Learning, Matplotlib, Seaborn,  Keras, Data Augmentation, Open CV

## Project outcome: 
The research confirmed the presence of gender bias, with the dataset disproportionately representing females and Caucasians, leading to biased outcomes in DeepFake detection. Videos of women with short hair or in formal attire were frequently misclassified as male due to the dataset's limited diversity. The fat anti-fat bias analysis highlighted societal misconceptions about obesity, with empirical results suggesting that certain physical traits led to biased judgments in the classification. The study proposed mitigation strategies, including expanding datasets to represent diverse physical traits and reducing reliance on stereotypical visual cues.

## Significance in the field of endeavor: 
This project provides valuable insights into the biases present in DeepFake technology, with broader implications for machine learning models used in media manipulation and AI ethics. By identifying key biases in gender and body image, it emphasizes the need for more inclusive datasets to prevent skewed AI outcomes. The research not only advances the understanding of bias in AI-generated content but also contributes to efforts aimed at improving fairness and accuracy in AI models across various domains, including entertainment, education, and security.

-	**Research Paper:** 
A comprehensive research paper was developed on this topic, accompanied by an extensive literature review to support the findings. Although the paper has not been submitted to any journal or conference, it provides in-depth analysis and insights. For a more detailed exploration, please refer to the attached link to the paper included.
Link: https://drive.google.com/file/d/14p9XeHOmLZ6wJguMJxzxkWrqOmc9JIwC/view?usp=drive_link

- **Github Link of Project:** https://github.com/trystine/BiasesInDeepfakeVideos

